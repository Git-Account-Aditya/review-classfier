{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e74ba48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os, sys\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Tuple, Literal, Optional\n",
    "\n",
    "from llm_model import ChatLLM\n",
    "from prompts.prompt_v1 import get_prompt_v1\n",
    "from prompts.prompt_v2 import get_prompt_v2\n",
    "from prompts.prompt_v3 import get_prompt_v3\n",
    "\n",
    "from structured_output import StructuredOutput  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b7a5c",
   "metadata": {},
   "source": [
    "### Load the processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa3cf597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text  cool  useful  \\\n",
       "0      5  My wife took me here on my birthday for breakf...     2       5   \n",
       "1      5  I have no idea why some people give bad review...     0       0   \n",
       "2      4  love the gyro plate. Rice is so good and I als...     0       1   \n",
       "\n",
       "   funny  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\admin\\Documents\\Review Prompting\\data\\yelp_preprocessed.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3819e63",
   "metadata": {},
   "source": [
    "### Split the data in features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40332f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data = data.loc[:101]\n",
    "x_train, y_train = subset_data.drop(columns=['stars']), subset_data['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01c25335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = ChatLLM(provider='groq', model_name='llama-3.1-8b-instant').model\n",
    "\n",
    "# create chain 1 using promptv1\n",
    "prompt1= get_prompt_v1()\n",
    "chain1 = prompt1 | model.with_structured_output(StructuredOutput)\n",
    "\n",
    "# create chain 2 using promptv2\n",
    "prompt2 = get_prompt_v2()\n",
    "chain2 = prompt2 | model.with_structured_output(StructuredOutput)\n",
    "\n",
    "# create chain 3 using promptv3\n",
    "prompt3 = get_prompt_v3()\n",
    "chain3 = prompt3 | model.with_structured_output(StructuredOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a75730",
   "metadata": {},
   "source": [
    "### Evaluation of multiple prompts on a subset of processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cdba281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['reactions', 'review_text'], input_types={}, partial_variables={}, template='\\n    You are an expert sentiment analysis system. Your task is to predict the star rating (1-5) for a given review.\\n\\n    Analyze the following review properties:\\n    Review Text: {review_text}\\n    Reactions: {reactions}\\n\\n    Output Instructions:\\n    - You MUST return a valid JSON object strictly following the schema below.\\n    - Do NOT return any preamble, explanation text, or markdown code blocks (like ```json).\\n    - Just return the raw JSON.\\n    ')\n",
       "| RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000163E44E1550>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000163E44E1D50>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'StructuredOutput', 'description': '', 'parameters': {'properties': {'predicted_stars': {'description': 'The predicted number of stars given by user to the product.', 'enum': [1, 2, 3, 4, 5], 'type': 'integer'}, 'explanation': {'description': 'The explanation for the predicted number of stars.', 'type': 'string'}}, 'required': ['predicted_stars', 'explanation'], 'type': 'object'}}}], 'ls_structured_output_format': {'kwargs': {'method': 'function_calling'}, 'schema': {'type': 'function', 'function': {'name': 'StructuredOutput', 'description': '', 'parameters': {'properties': {'predicted_stars': {'description': 'The predicted number of stars given by user to the product.', 'enum': [1, 2, 3, 4, 5], 'type': 'integer'}, 'explanation': {'description': 'The explanation for the predicted number of stars.', 'type': 'string'}}, 'required': ['predicted_stars', 'explanation'], 'type': 'object'}}}}, 'tool_choice': {'type': 'function', 'function': {'name': 'StructuredOutput'}}}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class 'structured_output.StructuredOutput'>])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4263d3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutput(predicted_stars=4, explanation=\"The review contains positive words like 'good' and 'funny', which suggests a high star rating. The reactions also support this, with 'funny' being a strong indicator of a positive review.\")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.invoke({\n",
    "    'reactions': {\n",
    "        'cool': '1',\n",
    "        'useful': '2',\n",
    "        'funny': '3'\n",
    "    },\n",
    "    'review_text': 'The movie wal good and funny'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc2bf0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutput(predicted_stars=3, explanation=\"The reviewer states a neutral opinion about the movie, neither praising nor criticizing it. The 'useful' reaction count is low, indicating the review may not be helpful in making a purchasing decision. Based on the neutral sentiment and lack of specific features or flaws, the predicted rating is 3, indicating a mediocre experience.\")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\n",
    "    'review_text': 'Movie was good',\n",
    "    'reactions': {\n",
    "        'cool': '1',\n",
    "        'useful': '2',\n",
    "        'funny': '3'\n",
    "    }}) \n",
    "\n",
    "chain3.invoke({\n",
    "    'review_text': 'Movie was good',\n",
    "    'reactions': {\n",
    "        'cool': '1',\n",
    "        'useful': '2',\n",
    "        'funny': '3'\n",
    "    }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd11169a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutput(predicted_stars=4, explanation=\"Based on the review content 'Movie was good', the overall sentiment is positive. Although the tone is neutral, the presence of positive keywords like 'good' hints at a high rating. Considering the reactions, many people found the review 'useful', further supporting a high rating.\")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\n",
    "    'review_text': 'Movie was good',\n",
    "    'reactions': {\n",
    "        'cool': '1',\n",
    "        'useful': '2',\n",
    "        'funny': '3'\n",
    "    }}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31373588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing review: 0\n",
      "processing review: 1\n",
      "processing review: 2\n",
      "processing review: 3\n",
      "processing review: 4\n",
      "processing review: 5\n",
      "processing review: 6\n",
      "processing review: 7\n",
      "processing review: 8\n",
      "processing review: 9\n",
      "processing review: 10\n",
      "processing review: 11\n",
      "processing review: 12\n",
      "processing review: 13\n",
      "processing review: 14\n",
      "processing review: 15\n",
      "processing review: 16\n",
      "processing review: 17\n",
      "processing review: 18\n",
      "processing review: 19\n",
      "processing review: 20\n",
      "processing review: 21\n",
      "processing review: 22\n",
      "processing review: 23\n",
      "processing review: 24\n",
      "processing review: 25\n",
      "processing review: 26\n",
      "processing review: 27\n",
      "processing review: 28\n",
      "processing review: 29\n",
      "processing review: 30\n",
      "processing review: 31\n",
      "processing review: 32\n",
      "processing review: 33\n",
      "processing review: 34\n",
      "processing review: 35\n",
      "processing review: 36\n",
      "processing review: 37\n",
      "processing review: 38\n",
      "processing review: 39\n",
      "processing review: 40\n",
      "processing review: 41\n",
      "processing review: 42\n",
      "processing review: 43\n",
      "processing review: 44\n",
      "processing review: 45\n",
      "processing review: 46\n",
      "processing review: 47\n",
      "processing review: 48\n",
      "processing review: 49\n",
      "processing review: 50\n",
      "processing review: 51\n",
      "processing review: 52\n",
      "processing review: 53\n",
      "processing review: 54\n",
      "processing review: 55\n",
      "processing review: 56\n",
      "processing review: 57\n",
      "processing review: 58\n",
      "processing review: 59\n",
      "processing review: 60\n",
      "processing review: 61\n",
      "processing review: 62\n",
      "processing review: 63\n",
      "processing review: 64\n",
      "processing review: 65\n",
      "processing review: 66\n",
      "processing review: 67\n",
      "processing review: 68\n",
      "processing review: 69\n",
      "processing review: 70\n",
      "processing review: 71\n",
      "processing review: 72\n",
      "processing review: 73\n",
      "processing review: 74\n",
      "processing review: 75\n",
      "processing review: 76\n",
      "processing review: 77\n",
      "processing review: 78\n",
      "processing review: 79\n",
      "processing review: 80\n",
      "processing review: 81\n",
      "processing review: 82\n",
      "processing review: 83\n",
      "processing review: 84\n",
      "processing review: 85\n",
      "processing review: 86\n",
      "processing review: 87\n",
      "processing review: 88\n",
      "processing review: 89\n",
      "processing review: 90\n",
      "processing review: 91\n",
      "processing review: 92\n",
      "processing review: 93\n",
      "processing review: 94\n",
      "processing review: 95\n",
      "processing review: 96\n",
      "processing review: 97\n",
      "processing review: 98\n",
      "processing review: 99\n",
      "processing review: 100\n",
      "processing review: 101\n",
      "Time taken:  181.76081156730652\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "outputs_path = \"results/outputs.json\"\n",
    "preds_path = \"results/predictions.csv\"\n",
    "\n",
    "# load once\n",
    "if os.path.exists(outputs_path):\n",
    "    with open(outputs_path, \"r\") as f:\n",
    "        outputs = json.load(f)\n",
    "else:\n",
    "    outputs = {}\n",
    "\n",
    "if os.path.exists(preds_path):\n",
    "    predictions = pd.read_csv(preds_path)\n",
    "else:\n",
    "    predictions = pd.DataFrame(\n",
    "        columns=[\"prompt1\", \"prompt2\", \"prompt3\", \"actual\"]\n",
    "    )\n",
    "\n",
    "def to_dict(result):\n",
    "    if hasattr(result, \"model_dump\"):\n",
    "        return result.model_dump()\n",
    "    if isinstance(result, dict):\n",
    "        return result\n",
    "    if isinstance(result, str):\n",
    "        try:\n",
    "            return json.loads(result)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"raw\": result}\n",
    "    return {\"raw\": str(result)}\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    print(f\"processing review: {i}\")\n",
    "    x_train_i = x_train.iloc[i]\n",
    "    review_text = x_train_i[\"text\"]\n",
    "\n",
    "    if review_text in outputs:\n",
    "        continue\n",
    "\n",
    "    reaction_payload = {\n",
    "        \"cool\": x_train_i[\"cool\"],\n",
    "        \"useful\": x_train_i[\"useful\"],\n",
    "        \"funny\": x_train_i[\"funny\"],\n",
    "    }\n",
    "\n",
    "    res1 = chain1.invoke({\"review_text\": review_text, \"reactions\": reaction_payload})\n",
    "    res2 = chain2.invoke({\"review_text\": review_text, \"reactions\": reaction_payload})\n",
    "    res3 = chain3.invoke({\"review_text\": review_text, \"reactions\": reaction_payload})\n",
    "\n",
    "    res1_dict = to_dict(res1)\n",
    "    res2_dict = to_dict(res2)\n",
    "    res3_dict = to_dict(res3)\n",
    "\n",
    "    new_row = [\n",
    "        res1_dict.get(\"predicted_stars\"),\n",
    "        res2_dict.get(\"predicted_stars\"),\n",
    "        res3_dict.get(\"predicted_stars\"),\n",
    "        y_train.iloc[i],\n",
    "    ]\n",
    "    predictions.loc[len(predictions)] = new_row\n",
    "\n",
    "    outputs[review_text] = {\n",
    "        \"prompt1\": res1_dict,\n",
    "        \"prompt2\": res2_dict,\n",
    "        \"prompt3\": res3_dict,\n",
    "    }\n",
    "\n",
    "    # ---- save after each iteration ----\n",
    "    with open(outputs_path, \"w\") as f:\n",
    "        json.dump(outputs, f, indent=2)\n",
    "    predictions.to_csv(preds_path, index=False)\n",
    "\n",
    "print(\"Time taken: \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94166cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1211495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf1453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
